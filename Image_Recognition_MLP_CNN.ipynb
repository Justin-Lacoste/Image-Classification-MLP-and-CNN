{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "### IMPORTS ###\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "HxicNYGmgP4C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "eF8NxZpHpz3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPK5Hxw-fyyv",
        "outputId": "54b332c0-caaa-499b-f2f9-9aae59f66785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 11s 0us/step\n",
            "Train: X=(50000, 3073), y=(50000, 10)\n",
            "Test: X=(10000, 3073), y=(10000, 10)\n"
          ]
        }
      ],
      "source": [
        "### LOAD AND PREPARE DATA ###\n",
        "\n",
        "#Load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "#Vectorize images\n",
        "x_train = np.array([np.float64(x.flatten()) for x in x_train])\n",
        "x_test = np.array([np.float64(x.flatten()) for x in x_test])\n",
        "\n",
        "\n",
        "#Normalize images\n",
        "x_train -= np.mean(x_train, axis = 0)\n",
        "x_train /= np.std(x_train, axis = 0)\n",
        "x_test -= np.mean(np.float64(x_test), axis = 0)\n",
        "x_test /= np.std(x_test, axis = 0)\n",
        "\n",
        "#One hot encoding of labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "#Insert '1' for bias\n",
        "x_train = np.insert(x_train, 0, [1] * len(x_train), axis=1)\n",
        "x_test = np.insert(x_test, 0, [1] * len(x_test), axis=1)\n",
        "\n",
        "\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiLayer Perceptron Implementation"
      ],
      "metadata": {
        "id": "GVIBrrIiqDuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic = lambda z: 1./ (1 + np.exp(-z))\n",
        "\n",
        "class MultiLayerPerceptron:\n",
        "\n",
        "  def __init__(self, activation_function, num_hidden_layers, hidden_layers_width):\n",
        "    self.activation_function = activation_function\n",
        "    self.num_hidden_layers = num_hidden_layers\n",
        "    self.hidden_layers_width = hidden_layers_width\n",
        "    self.loss_per_epoch = []\n",
        "\n",
        "\n",
        "    #Initialize weights with given number of hidden layers (0, 1 or 2)\n",
        "    if num_hidden_layers == 0:\n",
        "      self.w1 = np.random.rand(10, 3073)/1000\n",
        "\n",
        "    elif num_hidden_layers == 1:\n",
        "      if len(hidden_layers_width) != 1:\n",
        "        raise Exception(\"Invalid input: len(hidden_layers_width) != num_hidden_layers\")\n",
        "      self.w1 = np.random.rand(hidden_layers_width[0], 3073)/100\n",
        "      self.w2 = np.random.rand(10, hidden_layers_width[0])/100\n",
        "\n",
        "    elif num_hidden_layers == 2:\n",
        "      if len(hidden_layers_width) != 2:\n",
        "        raise Exception(\"Invalid input: len(hidden_layers_width) != num_hidden_layers\")\n",
        "      self.w1 = np.random.rand(hidden_layers_width[0], 3073)/1000\n",
        "      self.w2 = np.random.rand(hidden_layers_width[1], hidden_layers_width[0])/1000\n",
        "      self.w3 = np.random.rand(10, hidden_layers_width[1])/1000\n",
        "    else:\n",
        "      raise Exception(\"Unsupported number of hidden layers\")\n",
        "\n",
        "\n",
        "  def fit(self, x, y, learning_rate, epsilon, max_iters, batch_size):\n",
        "\n",
        "    num_of_batches = int(len(x)/batch_size)\n",
        "    x_batches = np.array_split(x, num_of_batches)\n",
        "    y_batches = np.array_split(y, num_of_batches)\n",
        "\n",
        "    #Gradient descent\n",
        "    norms = np.array([np.inf])\n",
        "    t = 0\n",
        "    print(\"Epochs: \")\n",
        "    \n",
        "    #RELU WITH 0 HIDDEN LAYERS\n",
        "    if self.activation_function == self.relu and self.num_hidden_layers == 0:\n",
        "      while np.any(norms > epsilon) and t < max_iters:\n",
        "          for batch in range(num_of_batches):\n",
        "            grad = self.relu_gradient(x_batches[batch], y_batches[batch])\n",
        "            self.w1 -= learning_rate * grad #* (1/num_of_batches)\n",
        "          t += 1\n",
        "          norms = np.array([np.linalg.norm(g) for g in grad])\n",
        "          print(t, end=' ')\n",
        "      print(\"\")\n",
        "      print(f\"{t} iterations performed\")\n",
        "      return\n",
        "\n",
        "    #RELU WITH 1 HIDDEN LAYERS\n",
        "    elif self.activation_function == self.relu and self.num_hidden_layers == 1:\n",
        "      while t < max_iters:\n",
        "          for batch in range(num_of_batches):\n",
        "            grad_w1, grad_w2 = self.relu_gradient(x_batches[batch], y_batches[batch])\n",
        "            self.w1 -= learning_rate * grad_w1 #* (1/num_of_batches)\n",
        "            self.w2 -= learning_rate * grad_w2 #* (1/num_of_batches)\n",
        "          t += 1\n",
        "          print(t, end=' ')\n",
        "      print(\"\")\n",
        "      print(f\"{t} iterations performed\")\n",
        "      return\n",
        "\n",
        "    #RELU WITH 2 HIDDEN LAYERS\n",
        "    elif self.activation_function == self.relu and self.num_hidden_layers == 2:\n",
        "      while t < max_iters:\n",
        "          for batch in range(num_of_batches):\n",
        "            grad_w1, grad_w2, grad_w3 = self.relu_gradient(x_batches[batch], y_batches[batch])\n",
        "            self.w1 -= learning_rate * grad_w1 #* (1/num_of_batches)\n",
        "            self.w2 -= learning_rate * grad_w2 #* (1/num_of_batches)\n",
        "            self.w3 -= learning_rate * grad_w3 #* (1/num_of_batches)\n",
        "          t += 1\n",
        "          print(t, end=' ')\n",
        "      print(\"\")\n",
        "      print(f\"{t} iterations performed\")\n",
        "      return\n",
        "\n",
        "    \n",
        "    #TAN_H WITH 0 HIDDEN LAYERS\n",
        "    if self.activation_function == self.tanh and self.num_hidden_layers == 0:\n",
        "      while np.any(norms > epsilon) and t < max_iters:\n",
        "          for batch in range(num_of_batches):\n",
        "            grad = self.tanh_gradient(x_batches[batch], y_batches[batch])\n",
        "            self.w1 -= learning_rate * grad * (1/num_of_batches)\n",
        "          t += 1\n",
        "          norms = np.array([np.linalg.norm(g) for g in grad])\n",
        "          print(t, end=' ')\n",
        "      print(\"\")\n",
        "      print(f\"{t} iterations performed\")\n",
        "      return\n",
        "\n",
        "    #TAN_H WITH 1 HIDDEN LAYERS\n",
        "    if self.activation_function == self.tanh and self.num_hidden_layers == 1:\n",
        "      while np.any(norms > epsilon) and t < max_iters:\n",
        "          for batch in range(num_of_batches):\n",
        "            grad_w1, grad_w2 = self.tanh_gradient(x_batches[batch], y_batches[batch])\n",
        "            self.w1 -= learning_rate * grad_w1 * (1/num_of_batches)\n",
        "            self.w2 -= learning_rate * grad_w2 * (1/num_of_batches)\n",
        "          t += 1\n",
        "          print(t, end=' ')\n",
        "      print(\"\")\n",
        "      print(f\"{t} iterations performed\")\n",
        "      return\n",
        "\n",
        "    #TAN_H WITH 2 HIDDEN LAYERS\n",
        "    if self.activation_function == self.tanh and self.num_hidden_layers == 2:\n",
        "      while np.any(norms > epsilon) and t < max_iters:\n",
        "          for batch in range(num_of_batches):\n",
        "            grad_w1, grad_w2, grad_w3 = self.tanh_gradient(x_batches[batch], y_batches[batch])\n",
        "            self.w1 -= learning_rate * grad_w1 * (1/num_of_batches)\n",
        "            self.w2 -= learning_rate * grad_w2 * (1/num_of_batches)\n",
        "            self.w3 -= learning_rate * grad_w3 * (1/num_of_batches)\n",
        "          t += 1\n",
        "          print(t, end=' ')\n",
        "      print(\"\")\n",
        "      print(f\"{t} iterations performed\")\n",
        "      return\n",
        "\n",
        "\n",
        "  def relu_gradient(self, x, y):\n",
        "\n",
        "    y_hat = self.predict(x)\n",
        "    self.loss_per_epoch.append(MultiLayerPerceptron.total_loss(y, y_hat))\n",
        "    N, D = x.shape\n",
        "\n",
        "    if self.num_hidden_layers == 0:\n",
        "      dy = y_hat - y\n",
        "      dw1 = np.matmul(np.transpose(dy), x)\n",
        "      return dw1\n",
        "\n",
        "    elif self.num_hidden_layers == 1:\n",
        "      dy = y_hat - y\n",
        "      dw = (np.dot(self.z1_for_gradient, dy) / N).T\n",
        "      dz = np.dot(dy, self.w2)\n",
        "      dv = (np.dot(x.T, dz * (self.q1_for_gradient > 0).astype(int).T) / N).T\n",
        "      return dv, dw\n",
        "    elif self.num_hidden_layers == 2:\n",
        "      dy = y_hat - y\n",
        "      dw3 = (np.dot(self.z2_for_gradient, dy) / N).T\n",
        "      dz2 = np.dot(dy, self.w3)\n",
        "      dw2 = ((np.dot(self.z1_for_gradient, dz2 * (self.q2_for_gradient > 0).astype(int).T)) / N).T\n",
        "      dz1 = np.dot(dz2 * (1 - (self.z2_for_gradient.T)**2), self.w2)\n",
        "      dw1 = ((np.dot(x.T, dz1 * (self.q1_for_gradient > 0).astype(int).T)) / N).T\n",
        "      return dw1, dw2, dw3\n",
        "\n",
        "\n",
        "\n",
        "  def tanh_gradient(self, x, y):\n",
        "    y_hat = self.predict(x)\n",
        "    self.loss_per_epoch.append(MultiLayerPerceptron.total_loss(y, y_hat))\n",
        "    N, D = x.shape\n",
        "\n",
        "    if self.num_hidden_layers == 0:\n",
        "      dy = y_hat - y\n",
        "      dw1 = np.matmul(np.transpose(dy), x)\n",
        "      return dw1\n",
        "\n",
        "    elif self.num_hidden_layers == 1:\n",
        "      dy = y_hat - y\n",
        "      dw = (np.dot(self.z1_for_gradient, dy) / N).T\n",
        "      dz = np.dot(dy, self.w2)\n",
        "      dv = (np.dot(x.T, dz * (1 - (self.z1_for_gradient.T)**2)) / N).T\n",
        "      return dv, dw\n",
        "\n",
        "    elif self.num_hidden_layers == 2:\n",
        "      dy = y_hat - y\n",
        "      dw3 = (np.dot(self.z2_for_gradient, dy) / N).T\n",
        "      dz2 = np.dot(dy, self.w3)\n",
        "      dw2 = (np.dot(self.z1_for_gradient, dz2 * (1 - (self.z2_for_gradient.T)**2)) / N).T\n",
        "      dz1 = np.dot(dz2 * (1 - (self.z2_for_gradient.T)**2), self.w2)\n",
        "      dw1 = ((np.dot(x.T, dz1 * (1 - (self.z1_for_gradient.T)**2))) / N).T\n",
        "      return dw1, dw2, dw3\n",
        "\n",
        "\n",
        "  def predict(self, x):\n",
        "\n",
        "    if self.num_hidden_layers == 0:\n",
        "      return self.softmax(np.transpose(np.dot(self.w1, np.transpose(x))))\n",
        "\n",
        "    elif self.num_hidden_layers == 1:\n",
        "      q1 = np.dot(self.w1, np.transpose(x))\n",
        "      z1 = self.activation_function(q1)\n",
        "      self.q1_for_gradient = q1\n",
        "      self.z1_for_gradient = z1\n",
        "      return self.softmax(np.transpose(np.dot(self.w2, z1)))\n",
        "    else:\n",
        "      q1 = np.dot(self.w1, np.transpose(x))\n",
        "      z1 = self.activation_function(q1)\n",
        "      self.q1_for_gradient = q1\n",
        "      self.z1_for_gradient = z1\n",
        "      q2 = np.matmul(self.w2, z1)\n",
        "      z2 = self.activation_function(q2)\n",
        "      self.q2_for_gradient = q1\n",
        "      self.z2_for_gradient = z1\n",
        "      return self.softmax(np.transpose(np.matmul(self.w3, z2)))\n",
        "\n",
        "  \n",
        "  @staticmethod\n",
        "  def relu(x):\n",
        "    return (x + np.abs(x))/2\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh(x):\n",
        "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "\n",
        "  @staticmethod\n",
        "  def softmax(x):\n",
        "    R, C = x.shape\n",
        "    for i in range(R):\n",
        "      if max(x[i]) > 709:\n",
        "        for j in range(C):\n",
        "          x[i][j] = np.exp(x[i][j])/denominator\n",
        "        highest_idx = np.argmax(x[i])\n",
        "        x[i][highest_idx] = 1\n",
        "        continue\n",
        "\n",
        "\n",
        "      denominator = sum([np.exp(j) for j in x[i]])\n",
        "      denominator = denominator if denominator > 0 else 1\n",
        "      for j in range(C):\n",
        "        x[i][j] = np.exp(x[i][j])/denominator\n",
        "    return x\n",
        "\n",
        "  @staticmethod\n",
        "  def accuracy(y, y_hat):\n",
        "\n",
        "    accurate_classifications = 0\n",
        "\n",
        "    for i, y in enumerate(y):\n",
        "      category = np.argmax(y)\n",
        "      predicted_category = np.argmax(y_hat[i])\n",
        "\n",
        "      if category == predicted_category:\n",
        "        accurate_classifications += 1\n",
        "\n",
        "    return accurate_classifications/len(y_hat)\n",
        "\n",
        "  @staticmethod\n",
        "  def total_loss(y, y_hat):\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for i, y in enumerate(y):\n",
        "      category = np.argmax(y)\n",
        "      predicted_value = y_hat[i][category]\n",
        "      loss += (-1 * np.log(predicted_value))\n",
        "\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "id": "rZxUINP8qC8O"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(709)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgE-Zejr9d5f",
        "outputId": "3b27ea2a-d23b-4d1a-9eda-9ad9f01ed556"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.218407461554972e+307"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle = list(zip(x_train, y_train))\n",
        "random.shuffle(shuffle)\n",
        "x_train, y_train = zip(*shuffle)\n",
        "num_train = 300\n",
        "\n",
        "\n",
        "mlp = MultiLayerPerceptron(MultiLayerPerceptron.relu, 2, [256, 256])\n",
        "\n",
        "preds = mlp.predict(x_train[:num_train])\n",
        "print(\"Initial Accuracy: \", MultiLayerPerceptron.accuracy(y_train[:num_train], preds)*100, \"%\")\n",
        "\n",
        "mlp.fit(x_train[:num_train], y_train[:num_train], learning_rate=0.0004, epsilon=0.0000001, max_iters=1000, batch_size=100)\n",
        "\n",
        "preds = mlp.predict(x_train[:num_train])\n",
        "print(\"Final Accuracy: \", MultiLayerPerceptron.accuracy(y_train[:num_train], preds)*100, \"%\")\n",
        "\n",
        "plt.plot(range(len(mlp.loss_per_epoch)), mlp.loss_per_epoch)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_1yaz8_PzH79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### WORKS WELL ###\n",
        "\n",
        "\n",
        "###1 layer tanh:\n",
        "# mlp.fit(x_train[:num_train], y_train[:num_train], learning_rate=0.01, epsilon=0.0000001, max_iters=2000, batch_size=100)\n",
        "# mlp.fit(x_train[:num_train], y_train[:num_train], learning_rate=0.05, epsilon=0.0000001, max_iters=1000, batch_size=1000)\n",
        "\n",
        "###2 layer tanh:\n",
        "#mlp.fit(x_train[:num_train], y_train[:num_train], learning_rate=0.1, epsilon=0.0000001, max_iters=3000, batch_size=100)\n",
        "\n",
        "\n",
        "###1 layer relu:\n",
        "#mlp.fit(x_train[:num_train], y_train[:num_train], learning_rate=0.006, epsilon=0.0000001, max_iters=3000, batch_size=20)\n",
        "\n"
      ],
      "metadata": {
        "id": "OOMgAtHRlt8G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "Ze6QHOblrGDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### SHUFFLE ###\n",
        "shuffle = list(zip(x_train, y_train))\n",
        "random.shuffle(shuffle)\n",
        "x_train, y_train = zip(*shuffle)\n",
        "\n",
        "shuffle = list(zip(x_test, y_test))\n",
        "random.shuffle(shuffle)\n",
        "x_test, y_test = zip(*shuffle)"
      ],
      "metadata": {
        "id": "cbuxpZN6WCMb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1"
      ],
      "metadata": {
        "id": "vyaWOl9eVxkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 0 HIDDEN-LAYER TRAINING ###\n",
        "mlp_0 = MultiLayerPerceptron(MultiLayerPerceptron.relu, 0, [])\n",
        "mlp_0.fit(x_train, y_train, learning_rate=0.0000001, epsilon=0.0000001, max_iters=20, batch_size=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCQ5DHxfrNWT",
        "outputId": "d6aaf526-673c-4388-ecc3-d4d950e0b0e5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
            "20 iterations performed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 1 HIDDEN-LAYER TRAINING ###\n",
        "mlp_0 = MultiLayerPerceptron(MultiLayerPerceptron.relu, 1, [256])\n",
        "mlp_0.fit(x_train, y_train, learning_rate=0.0000001, epsilon=0.006, max_iters=20, batch_size=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbFu_YHCinXx",
        "outputId": "b42d8602-25b0-41e5-86be-64f125917c62"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \n",
            "20 iterations performed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(mlp_0.loss_per_epoch)), mlp_0.loss_per_epoch)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6b-FJW2iXtqT",
        "outputId": "a57111df-abbb-4a98-afbc-f5487f067bab"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_train = mlp_0.predict(x_train)\n",
        "preds_test = mlp_0.predict(x_test)\n",
        "print(\"0 Hidden-Layer Training Accuracy: \", MultiLayerPerceptron.accuracy(y_train, preds_train)*100, \"%\")\n",
        "print(\"0 Hidden-Layer Test Accuracy: \", MultiLayerPerceptron.accuracy(y_test, preds_test)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHb35g0KWa9I",
        "outputId": "0b8cf349-7abf-4b2e-c0a2-4e86cd997017"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Hidden-Layer Training Accuracy:  33.662 %\n",
            "0 Hidden-Layer Test Accuracy:  33.6 %\n"
          ]
        }
      ]
    }
  ]
}